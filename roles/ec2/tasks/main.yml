---
- name: Generate SSH key pair for ec2
  ec2_key:
    name: "{{ simplye_instance_name }}"
    region: "{{ aws_region }}"
  register: ec2_key

- name: Save private key to local admins .ssh directory
  copy:
    content: "{{ ec2_key.key.private_key }}"
    dest: "~/.ssh/{{ simplye_instance_name }}.pem"
    mode: 0600
  when: ec2_key.changed

- name: Create ECS cluster
  ecs_cluster:
    name: "{{ simplye_role }}-{{ simplye_instance_name }}-ecs"
    region: "{{ aws_region }}"
    state: present

- name: Create security group for EC2 insance and open SSH port to the ansible control machine
  ec2_group:
    name: "EC2-{{ simplye_role }}-{{ simplye_instance_name }}"
    description: "Firewall rules for the {{ simplye_role }}-{{ simplye_instance_name }} RDS instance"
    region: "{{ aws_region }}"
    rules:
      - proto: all
        from_port: all
        to_port: all
        cidr_ip: 0.0.0.0/0
    rules_egress:
      - proto: all
        from_port: all
        to_port: all
        cidr_ip: 0.0.0.0/0
  register: ec2_sg
- debug: var=ec2_sg.group_id

- name: Get a list of subnets to use in EC2 creation
  ec2_vpc_subnet_facts:
    region: "{{ aws_region }}"
  register: subnet_facts

- name: Display all variables/facts - use -vvv to see output
  debug:
    var: hostvars['localhost']
    verbosity: 3

- set_fact:
    subnet_ids: "[ '{{ subnet_facts.subnets[0].id }}', '{{ subnet_facts.subnets[1].id }}', '{{ subnet_facts.subnets[2].id }}']"

- name: Create a new server instance in AWS EC2 if none exist with tag "{{ simplye_role }}-{{ simplye_instance_name }}"
  local_action:
    module: ec2
    wait: yes
    wait_timeout: 600
    region: "{{ aws_region }}"
    instance_type: "{{ ec2_instance_type }}"
    exact_count: 1
    count_tag:
      Environment: "{{ simplye_environment }}"
      Type: "{{ simplye_role }}"
      Name: "{{ simplye_role }}-{{ simplye_instance_name }}"
    instance_tags: '{"Name":"{{ simplye_role }}-{{ simplye_instance_name }}","Type":"{{ simplye_role }}","Environment":"{{ simplye_environment }}"}'
    key_name: "{{ simplye_instance_name }}"
    group_id: "{{ ec2_sg.group_id }}"
    image: "{{ ec2_image }}"
    vpc_subnet_id: "{{ subnet_ids|random }}"
    assign_public_ip: yes
    instance_profile_name: ecsInstanceRole
    user_data: |
               #!/bin/sh
               echo "ECS_CLUSTER={{ simplye_role }}-{{ simplye_instance_name }}-ecs" >> /etc/ecs/ecs.config
               echo vm.max_map_count=262144 | sudo tee -a /etc/sysctl.conf
    volumes:
    - device_name: /dev/xvda
      device_type: gp2
      volume_size: "{{ ec2_volume_size }}"
      delete_on_termination: true
  register: ec2

- debug: var=item
  with_items: "{{ ec2.instances }}"

- name: Add instance to host group in working memory
  add_host: hostname="{{ item.public_ip }}" groupname="{{ simplye_role }}-servers" ansible_ssh_private_key_file="~/.ssh/{{ simplye_instance_name }}.pem"
  with_items:
    - "{{ ec2.instances }}"
    - "{{ ec2.tagged_instances }}"

- name: Add instance ID as playbook fact
  set_fact:
    ec2_instance_id: "{{ item.id }}"
  with_items:
    - "{{ ec2.instances }}"
    - "{{ ec2.tagged_instances }}"

- name: Associate an Elastic IP with the new EC2 instance
  ec2_eip:
    region: "{{ aws_region }}"
    device_id: "{{ ec2_instance_id  }}"
  register: eip

- debug: var=item
  with_items: "{{ ec2.instances }}"

- name: Add instance info as playbook facts
  set_fact:
    ec2_ip: "{{ eip.public_ip }}"
    ec2_private_ip: "{{ item.private_ip }}"
  with_items:
    - "{{ ec2.instances }}"
    - "{{ ec2.tagged_instances }}"

- name: Check SSH to make sure the instance boots
  wait_for: host={{ item.public_ip }} port=22 delay=60 timeout=320 state=started
  with_items: "{{ ec2.instances }}"

- debug: var=ec2_private_ip
